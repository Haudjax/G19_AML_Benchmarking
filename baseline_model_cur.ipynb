{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c93ff8ca",
      "metadata": {
        "id": "c93ff8ca"
      },
      "source": [
        "# Benchmarking Tabular ML Datasets\n",
        "Thom, Jakob and Marit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "537691d1",
      "metadata": {
        "id": "537691d1"
      },
      "outputs": [],
      "source": [
        "from tabpfn_client import TabPFNClassifier\n",
        "from tabpfn.constants import ModelVersion\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "#import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79e622dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# To use TabPFN external servers (TabPFN_client), create an account on Prior\n",
        "PRIOR_TOKEN = '<copy token from prior website>'\n",
        "tabpfn_client.set_access_token(PRIOR_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd2155cc",
      "metadata": {
        "id": "bd2155cc"
      },
      "source": [
        "## Load in Data, will not change data cleaning logic compared to other models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "3b3df1ff",
      "metadata": {
        "id": "3b3df1ff"
      },
      "outputs": [],
      "source": [
        "def load_df(filename, foldername='aml-2025-benchmarking-tabular-ml-datasets'):\n",
        "    return pd.read_csv(f'{foldername}/{filename}', header=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "eafbdb6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "covtype_test = load_df('covtype_test.csv')\n",
        "covtype_train = load_df('covtype_train.csv')\n",
        "heloc_test = load_df('heloc_test.csv')\n",
        "heloc_train = load_df('heloc_train.csv')\n",
        "higgs_test = load_df('higgs_test.csv')\n",
        "higgs_train = load_df('higgs_train.csv')\n",
        "\n",
        "# Make all target columns have the name 'target'\n",
        "covtype_train.rename(columns={'Cover_Type' : 'label'}, inplace=True)\n",
        "heloc_train.rename(columns={'RiskPerformance' : 'label'}, inplace=True)\n",
        "higgs_train.rename(columns={'Label' : 'label'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "668aef96",
      "metadata": {},
      "outputs": [],
      "source": [
        "tables_test = [covtype_test, heloc_test, higgs_test]\n",
        "tables_train = [covtype_train, heloc_train, higgs_train]\n",
        "names = ['CoverType', 'HELOC', 'Higgs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "b38e1037",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Labels to convert\n",
        "binary_labels = {\n",
        "    'Bad': 1,\n",
        "    'Good': 0,\n",
        "    's': 1,\n",
        "    'b': 0\n",
        "    }\n",
        "\n",
        "def clean_and_combine(tables, names, binary_labels = None):\n",
        "    \n",
        "    cleaned_tables = []\n",
        "\n",
        "    for table, name in zip(tables, names):\n",
        "        t = table.copy()\n",
        "\n",
        "        # Get numerical columns for this specific table\n",
        "        numerical_cols = t.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "        # Clean missing values based on domain and remove id column\n",
        "        if name == 'HELOC':\n",
        "            for col in numerical_cols:\n",
        "                t.loc[t[col] < 0, col] = np.nan\n",
        "        elif name == 'HIGGS':\n",
        "            t.replace(-999.0, np.nan, inplace=True)\n",
        "            t = t.drop('EventId')\n",
        "\n",
        "        # Add domain name\n",
        "        t['Domain'] = name\n",
        "        cleaned_tables.append(t)\n",
        "        \n",
        "    unified_df = pd.concat(cleaned_tables, ignore_index=True)\n",
        "\n",
        "    # Handle target labels if provided (Training Data)\n",
        "    if binary_labels:\n",
        "        unified_df['label'] = unified_df['label'].astype(str).replace(binary_labels)       # As string first to prevent downcasting warning\n",
        "        unified_df['label'] = unified_df['label'].astype(int)\n",
        "    return unified_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "93d83a41",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = clean_and_combine(tables_train, names, binary_labels)\n",
        "df_test = clean_and_combine(tables_test, names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "40d7eae1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_dataset(df, target_col = \"label\", id_col=None, train_size=1000, random_state=42, dataset_name=\"\"):\n",
        "\n",
        "    # Drop ID column\n",
        "    if id_col is not None and id_col in df.columns:\n",
        "        df = df.drop(columns=[id_col])\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop(columns=[target_col])\n",
        "    \n",
        "    unified_columns_list = X.columns.tolist() # This list is needed for making predictions later (column order and nr of columns needs to be the same)\n",
        "\n",
        "    y = df[target_col]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        train_size=train_size,\n",
        "        stratify=y,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    print(f\"\\n Fitting TabPFN model on {dataset_name or target_col}, shape: {X_train.shape}\")\n",
        "    \n",
        "    clf = TabPFNClassifier()\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Making Predictions with TabPFN-client\")\n",
        "    \n",
        "    # Validating results only on 10000 rows, to get an accuracy measure, but not waste too many TabPFN credits - not ideal but local (train set validation) accuracy not so important.\n",
        "    X_test = X_test.iloc[-10000:]\n",
        "    y_test = y_test.iloc[-10000:]\n",
        "\n",
        "    # Predictions in Batches, to see completion time\n",
        "    n_samples = X_test.shape[0]\n",
        "    print(n_samples)\n",
        "    batch_size = 10000\n",
        "    n_batches = math.ceil(n_samples / batch_size)\n",
        "    print(f\"batch size / batches: {batch_size}/{n_batches}\")\n",
        "    predictions = []\n",
        "\n",
        "    for i, start in enumerate(range(0, n_samples, batch_size), 1):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        X_batch = X_test.iloc[start:end]\n",
        "        t0 = time.time()\n",
        "        pred_batch = clf.predict(X_batch)\n",
        "        t1 = time.time()\n",
        "        batches_left = n_batches - i\n",
        "        print(f\"Batch {i}-{n_batches} ({start}-{end}) done in {t1-t0:.2f}s, {batches_left} batches left.\")\n",
        "        \n",
        "        predictions.append(pred_batch)\n",
        "\n",
        "    return (X_train, X_test, y_train, y_test), clf, unified_columns_list, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "8916b6c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Fitting TabPFN model on Unified, shape: (12500, 109)\n",
            "Making Predictions with TabPFN-client\n",
            "10000\n",
            "batch size / batches: 10000/1\n",
            "(10000, 109)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| [00:14<00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1-1 (0-10000) done in 16.70s, 0 batches left.\n"
          ]
        }
      ],
      "source": [
        "tabpfn_splits, tabpfn_clf, unified_columns_list, preds = evaluate_dataset(\n",
        "    df_train,\n",
        "    id_col='EventId',           # leave out id column (removed it before actually, but kept the option in the function)\n",
        "    train_size=12500,           \n",
        "    dataset_name=\"Unified\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "dcea3f30",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9327"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(tabpfn_splits[3],preds[0]) #Score on a subset of the Training set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a306bb23",
      "metadata": {},
      "source": [
        "# Make predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a08db5",
      "metadata": {},
      "source": [
        "**TabPFN-Client (PRIOR labs) credit calculation:**\n",
        "\n",
        "- 100,000,000 Credits per day\n",
        "\n",
        "- Cost of run: api_cost = max((num_train_rows + num_test_rows) * num_cols * n_estimators, 5000) ---> **Can't have more than 50,000 rows per call (model restriction)**\n",
        "\n",
        "Therefore to conduct predictions on test set, will choose batch_size = 40,000, with num_train_rows being 12,500, each batch of predictions cost a bit less than 50,000,000 credits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "3fa0e182",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_predictions(data: pd.DataFrame, clf, feature_cols: list, batch_size: int , id_col: str = 'EventId') -> pd.DataFrame:\n",
        "    data_original = data.copy()\n",
        "    \n",
        "    if id_col is not None and id_col in data.columns:\n",
        "        data = data.drop(columns=[id_col])\n",
        "\n",
        "\n",
        "    data = data[feature_cols]\n",
        "\n",
        "    # Predictions in Batches, to see completion time\n",
        "    n_samples = data.shape[0]\n",
        "    print(n_samples)\n",
        "    n_batches = math.ceil(n_samples / batch_size)\n",
        "    print(f\"batch size / batches: {batch_size}/{n_batches}\")\n",
        "    predictions = []\n",
        "\n",
        "    for i, start in enumerate(range(0, n_samples, batch_size), 1):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        X_batch = data.iloc[start:end]\n",
        "        print(X_batch.shape)\n",
        "        t0 = time.time()\n",
        "        pred_batch = clf.predict(X_batch)\n",
        "        t1 = time.time()\n",
        "        batches_left = n_batches - i\n",
        "        print(f\"Batch {i}-{n_batches} ({start}-{end}) done in {t1-t0:.2f}s, {batches_left} batches left.\")\n",
        "        \n",
        "        predictions.append(pred_batch)\n",
        "\n",
        "    results_df = data_original\n",
        "\n",
        "    return results_df, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "b5754285",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79546\n",
            "batch size / batches: 40000/2\n",
            "(40000, 109)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| [00:18<00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1-2 (0-40000) done in 30.69s, 1 batches left.\n",
            "(39546, 109)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| [00:18<00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 2-2 (40000-79546) done in 26.51s, 0 batches left.\n"
          ]
        }
      ],
      "source": [
        "df_results, preds_test = make_predictions(df_test, tabpfn_clf, unified_columns_list, 40000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "e900e223",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating output df\n",
        "np_preds_test = np.concatenate(preds_test)\n",
        "df_preds_test = pd.DataFrame(np_preds_test, columns=['Prediction'])\n",
        "df_preds_test['ID'] = df_preds_test.index + 1\n",
        "df_preds_test[['ID', 'Prediction']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "1a27eb2b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created submission file: base_combined_test_submission.csv, DON'T FORGET TO DELETE THE EMPTY LINE FROM END!\n"
          ]
        }
      ],
      "source": [
        "# Creating output .csv\n",
        "output_filename = \"base_combined_test_submission.csv\"\n",
        "df_preds_test[['ID', 'Prediction']].to_csv(output_filename, index=False)\n",
        "print(f\"Successfully created submission file: {output_filename}, DON'T FORGET TO DELETE THE EMPTY LINE FROM END!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
