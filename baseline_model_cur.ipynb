{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c93ff8ca",
      "metadata": {
        "id": "c93ff8ca"
      },
      "source": [
        "# Benchmarking Tabular ML Datasets\n",
        "Thom, Jakob and Marit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "537691d1",
      "metadata": {
        "id": "537691d1"
      },
      "outputs": [],
      "source": [
        "import tabpfn_client\n",
        "from tabpfn_client import TabPFNClassifier\n",
        "from tabpfn.constants import ModelVersion\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "#import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "79e622dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# To use TabPFN external servers (TabPFN_client), create an account on Prior\n",
        "PRIOR_TOKEN = '<copy paste your token from PRIOR LABS>'\n",
        "tabpfn_client.set_access_token(PRIOR_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd2155cc",
      "metadata": {
        "id": "bd2155cc"
      },
      "source": [
        "## Load in Data, will not change data cleaning logic compared to other models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3b3df1ff",
      "metadata": {
        "id": "3b3df1ff"
      },
      "outputs": [],
      "source": [
        "def load_df(filename, foldername='aml-2025-benchmarking-tabular-ml-datasets'):\n",
        "    return pd.read_csv(f'{foldername}/{filename}', header=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "eafbdb6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "covtype_test = load_df('covtype_test.csv')\n",
        "covtype_train = load_df('covtype_train.csv')\n",
        "heloc_test = load_df('heloc_test.csv')\n",
        "heloc_train = load_df('heloc_train.csv')\n",
        "higgs_test = load_df('higgs_test.csv')\n",
        "higgs_train = load_df('higgs_train.csv')\n",
        "\n",
        "# Make all target columns have the name 'target'\n",
        "covtype_train.rename(columns={'Cover_Type' : 'label'}, inplace=True)\n",
        "heloc_train.rename(columns={'RiskPerformance' : 'label'}, inplace=True)\n",
        "higgs_train.rename(columns={'Label' : 'label'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "668aef96",
      "metadata": {},
      "outputs": [],
      "source": [
        "tables_test = [covtype_test, heloc_test, higgs_test]\n",
        "tables_train = [covtype_train, heloc_train, higgs_train]\n",
        "names = ['CoverType', 'HELOC', 'Higgs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b38e1037",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Labels to convert\n",
        "binary_labels = {\n",
        "    'Bad': 1,\n",
        "    'Good': 0,\n",
        "    's': 1,\n",
        "    'b': 0\n",
        "    }\n",
        "\n",
        "def clean_and_combine(tables, names, binary_labels = None):\n",
        "    \n",
        "    cleaned_tables = []\n",
        "\n",
        "    for table, name in zip(tables, names):\n",
        "        t = table.copy()\n",
        "\n",
        "        # Get numerical columns for this specific table\n",
        "        numerical_cols = t.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "        # Clean missing values based on domain and remove id column\n",
        "        if name == 'HELOC':\n",
        "            for col in numerical_cols:\n",
        "                t.loc[t[col] < 0, col] = np.nan\n",
        "        elif name == 'HIGGS':\n",
        "            t.replace(-999.0, np.nan, inplace=True)\n",
        "            t = t.drop('EventId')\n",
        "\n",
        "        # Add domain name\n",
        "        t['Domain'] = name\n",
        "        cleaned_tables.append(t)\n",
        "        \n",
        "    unified_df = pd.concat(cleaned_tables, ignore_index=True)\n",
        "\n",
        "    # Handle target labels if provided (Training Data)\n",
        "    if binary_labels:\n",
        "        unified_df['label'] = unified_df['label'].astype(str).replace(binary_labels)       # As string first to prevent downcasting warning\n",
        "        unified_df['label'] = unified_df['label'].astype(int)\n",
        "    return unified_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "93d83a41",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = clean_and_combine(tables_train, names, binary_labels)\n",
        "df_train = df_train.drop(columns=['Weight'])\n",
        "df_test = clean_and_combine(tables_test, names)\n",
        "df_test = df_test.drop(columns=['Weight'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6526bf9c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Domain\n",
              "Higgs        175000\n",
              "CoverType     58101\n",
              "HELOC          9413\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['Domain'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "40d7eae1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit_tabpfn(df, target_col = \"label\", id_col=None, train_size=1000, random_state=42, dataset_name=\"\"):\n",
        "\n",
        "    # Drop ID column\n",
        "    if id_col is not None and id_col in df.columns:\n",
        "        df = df.drop(columns=[id_col])\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop(columns=[target_col])\n",
        "    \n",
        "    unified_columns_list = X.columns.tolist() # This list is needed for making predictions later (column order and nr of columns needs to be the same)\n",
        "\n",
        "    y = df[target_col]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        train_size=train_size,\n",
        "        stratify=y,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    print(f\"\\n Fitting TabPFN model on {dataset_name or target_col}, shape: {X_train.shape}\")\n",
        "    \n",
        "    clf = TabPFNClassifier()\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Making Predictions with TabPFN-client\")\n",
        "    \n",
        "    # Validating results only on 10000 rows, to get an accuracy measure, but not waste too many TabPFN credits - not ideal but local (train set validation) accuracy not so important.\n",
        "    X_test_small = X_test.iloc[-10000:]\n",
        "    y_test_small = y_test.iloc[-10000:]\n",
        "\n",
        "    \n",
        "\n",
        "    # Predictions in Batches, to see completion time\n",
        "    n_samples = X_test_small.shape[0]\n",
        "    print(n_samples)\n",
        "    batch_size = 10000\n",
        "    n_batches = math.ceil(n_samples / batch_size)\n",
        "    print(f\"batch size / batches: {batch_size}/{n_batches}\")\n",
        "    predictions = []\n",
        "\n",
        "    for i, start in enumerate(range(0, n_samples, batch_size), 1):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        X_batch = X_test_small.iloc[start:end]\n",
        "        t0 = time.time()\n",
        "        pred_batch = clf.predict(X_batch)\n",
        "        t1 = time.time()\n",
        "        batches_left = n_batches - i\n",
        "        print(f\"Batch {i}-{n_batches} ({start}-{end}) done in {t1-t0:.2f}s, {batches_left} batches left.\")\n",
        "        \n",
        "        predictions.append(pred_batch)\n",
        "\n",
        "    return (X_train, X_test, y_train, y_test, X_test_small, y_test_small), clf, unified_columns_list, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8916b6c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Fitting TabPFN model on Unified, shape: (12500, 108)\n",
            "Making Predictions with TabPFN-client\n",
            "10000\n",
            "batch size / batches: 10000/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| [00:08<00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1-1 (0-10000) done in 10.16s, 0 batches left.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tabpfn_splits, tabpfn_clf, unified_columns_list, preds = fit_tabpfn(\n",
        "    df_train,\n",
        "    id_col='EventId',           # leave out id column (removed it before actually, but kept the option in the function)\n",
        "    train_size=12500,           \n",
        "    dataset_name=\"Unified\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "dcea3f30",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy on Validation Set: 0.8088\n"
          ]
        }
      ],
      "source": [
        "print(f\"Overall Accuracy on Validation Set: {accuracy_score(tabpfn_splits[5],preds[0])}\") #Score on a subset of the Training set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfc33eb0",
      "metadata": {},
      "source": [
        "# Assessing Model Performance Across Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f76097e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine X_test and y_test (split from df_train)\n",
        "df_validation = tabpfn_splits[1].copy()\n",
        "df_validation['label'] = tabpfn_splits[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f1f0ff9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combining df_validation enables us to get X, y for each individual dataset\n",
        "df_validation_cov = df_validation[df_validation['Domain'] == \"CoverType\"]\n",
        "df_validation_heloc = df_validation[df_validation['Domain'] == \"HELOC\"]\n",
        "df_validation_higgs = df_validation[df_validation['Domain'] == \"Higgs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2e2c587d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_dataset(tabpfn_fit, df, feature_cols, target_col = \"label\", id_col=None, batch_size=1000, random_state=42, dataset_name=\"\"):\n",
        "    \n",
        "    # Drop ID column\n",
        "    if id_col is not None and id_col in df.columns:\n",
        "        df = df.drop(columns=[id_col])\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df.drop(columns=[target_col])\n",
        "    X = X[feature_cols]\n",
        "\n",
        "    y = df[target_col]\n",
        "\n",
        "    X_val_discarded, X_val_sample, y_val_discarded, y_val_sample = train_test_split(\n",
        "    X, y,\n",
        "    test_size=batch_size,\n",
        "    stratify=y,\n",
        "    random_state=random_state\n",
        "    )\n",
        "\n",
        "    print(f\"\\n Making predictions on {dataset_name or target_col}, shape: {X_val_sample.shape}\")\n",
        "    # Predictions in Batches, to see completion time\n",
        "    n_samples = X_val_sample.shape[0]\n",
        "    n_batches = math.ceil(n_samples / batch_size)\n",
        "    print(f\"batch size / batches: {batch_size}/{n_batches}\")\n",
        "    \n",
        "    predictions = []\n",
        "\n",
        "    for i, start in enumerate(range(0, n_samples, batch_size), 1):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        X_batch = X_val_sample.iloc[start:end]\n",
        "        t0 = time.time()\n",
        "        pred_batch = tabpfn_fit.predict(X_batch)\n",
        "        t1 = time.time()\n",
        "        batches_left = n_batches - i\n",
        "        print(f\"Batch {i}-{n_batches} ({start}-{end}) done in {t1-t0:.2f}s, {batches_left} batches left.\")\n",
        "        \n",
        "        predictions.append(pred_batch)\n",
        "\n",
        "    return predictions, y_val_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "64fbeeaf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Making predictions on CoverType, shape: (10000, 108)\n",
            "batch size / batches: 10000/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| [00:08<00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1-1 (0-10000) done in 14.05s, 0 batches left.\n",
            "\n",
            " Making predictions on HELOC, shape: (5000, 108)\n",
            "batch size / batches: 5000/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| [00:07<00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1-1 (0-5000) done in 9.01s, 0 batches left.\n",
            "\n",
            " Making predictions on Higgs, shape: (10000, 108)\n",
            "batch size / batches: 10000/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| [00:08<00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1-1 (0-10000) done in 11.37s, 0 batches left.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "preds_cov, y_preds_cov = evaluate_dataset(tabpfn_clf, df_validation_cov, unified_columns_list, id_col='EventId', batch_size=10000, random_state=42, dataset_name=\"CoverType\")\n",
        "preds_heloc, y_preds_heloc = evaluate_dataset(tabpfn_clf, df_validation_heloc, unified_columns_list, id_col='EventId', batch_size=5000, random_state=42, dataset_name=\"HELOC\")\n",
        "preds_higgs, y_preds_higgs = evaluate_dataset(tabpfn_clf, df_validation_higgs, unified_columns_list, id_col='EventId', batch_size=10000, random_state=42, dataset_name=\"Higgs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8973095d",
      "metadata": {},
      "source": [
        "### Results across Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "b433cde4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy on Validation Set: 0.8088\n"
          ]
        }
      ],
      "source": [
        "print(f\"Overall Accuracy on Validation Set: {accuracy_score(tabpfn_splits[5],preds[0])}\") #Score on a subset of the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "263db50f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on CoverType: 0.7566\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy on CoverType: {accuracy_score(preds_cov[0], y_preds_cov)}\") #Score on a subset of the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6afb3c02",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on Heloc: 0.705\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy on Heloc: {accuracy_score(preds_heloc[0], y_preds_heloc)}\") #Score on a subset of the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "793c2efe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on Higgs: 0.836\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy on Higgs: {accuracy_score(preds_higgs[0], y_preds_higgs)}\") #Score on a subset of the Training set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bacb4224",
      "metadata": {},
      "source": [
        "# Combine into CSVs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ef52428",
      "metadata": {},
      "source": [
        "### CSVs used for results validation for poster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "1adf2b70",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created submission file: combined_validation.csv\n"
          ]
        }
      ],
      "source": [
        "# Combined dataset\n",
        "csv_combined = tabpfn_splits[4][['Domain']].copy()\n",
        "csv_combined['label'] = preds[0]\n",
        "csv_combined['prediction'] = tabpfn_splits[5]\n",
        "\n",
        "# Creating output .csv\n",
        "output_filename = \"combined_validation.csv\"\n",
        "csv_combined.to_csv(output_filename, index=False)\n",
        "print(f\"Successfully created submission file: {output_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "013f0c1c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created submission file: covertype_validation.csv\n"
          ]
        }
      ],
      "source": [
        "# Combined dataset\n",
        "csv_cov = pd.DataFrame({\n",
        "    'label': y_preds_cov,\n",
        "    'Prediction': preds_cov[0],\n",
        "    'Domain': 'CoverType'\n",
        "})\n",
        "\n",
        "# Creating output .csv\n",
        "output_filename = \"covertype_validation.csv\"\n",
        "csv_cov.to_csv(output_filename, index=False)\n",
        "print(f\"Successfully created submission file: {output_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "d6e1d729",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created submission file: heloc_validation.csv\n"
          ]
        }
      ],
      "source": [
        "# Combined dataset\n",
        "csv_heloc = pd.DataFrame({\n",
        "    'label': y_preds_heloc,\n",
        "    'Prediction': preds_heloc[0],\n",
        "    'Domain': 'HELOC'\n",
        "})\n",
        "\n",
        "# Creating output .csv\n",
        "output_filename = \"heloc_validation.csv\"\n",
        "csv_heloc.to_csv(output_filename, index=False)\n",
        "print(f\"Successfully created submission file: {output_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "94824480",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created submission file: higgs_validation.csv\n"
          ]
        }
      ],
      "source": [
        "# Combined dataset\n",
        "csv_higgs = pd.DataFrame({\n",
        "    'label': y_preds_higgs,\n",
        "    'Prediction': preds_higgs[0],\n",
        "    'Domain': 'Higgs'\n",
        "})\n",
        "\n",
        "# Creating output .csv\n",
        "output_filename = \"higgs_validation.csv\"\n",
        "csv_higgs.to_csv(output_filename, index=False)\n",
        "print(f\"Successfully created submission file: {output_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a306bb23",
      "metadata": {},
      "source": [
        "# Make predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a08db5",
      "metadata": {},
      "source": [
        "**TabPFN-Client (PRIOR labs) credit calculation:**\n",
        "\n",
        "- 100,000,000 Credits per day\n",
        "\n",
        "- Cost of run: api_cost = max((num_train_rows + num_test_rows) * num_cols * n_estimators, 5000) ---> **Can't have more than 50,000 rows per call (model restriction)**\n",
        "\n",
        "Therefore to conduct predictions on test set, will choose batch_size = 40,000, with num_train_rows being 12,500, each batch of predictions cost a bit less than 50,000,000 credits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fa0e182",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_predictions(data: pd.DataFrame, clf, feature_cols: list, batch_size: int , id_col: str = 'EventId') -> pd.DataFrame:\n",
        "    data_original = data.copy()\n",
        "    \n",
        "    if id_col is not None and id_col in data.columns:\n",
        "        data = data.drop(columns=[id_col])\n",
        "\n",
        "\n",
        "    data = data[feature_cols]\n",
        "\n",
        "    # Predictions in Batches, to see completion time\n",
        "    n_samples = data.shape[0]\n",
        "    print(n_samples)\n",
        "    n_batches = math.ceil(n_samples / batch_size)\n",
        "    print(f\"batch size / batches: {batch_size}/{n_batches}\")\n",
        "    predictions = []\n",
        "\n",
        "    for i, start in enumerate(range(0, n_samples, batch_size), 1):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        X_batch = data.iloc[start:end]\n",
        "        print(X_batch.shape)\n",
        "        t0 = time.time()\n",
        "        pred_batch = clf.predict(X_batch)\n",
        "        t1 = time.time()\n",
        "        batches_left = n_batches - i\n",
        "        print(f\"Batch {i}-{n_batches} ({start}-{end}) done in {t1-t0:.2f}s, {batches_left} batches left.\")\n",
        "        \n",
        "        predictions.append(pred_batch)\n",
        "\n",
        "    results_df = data_original\n",
        "\n",
        "    return results_df, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5754285",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results, preds_test = make_predictions(df_test, tabpfn_clf, unified_columns_list, 40000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e900e223",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating output df\n",
        "np_preds_test = np.concatenate(preds_test)\n",
        "df_preds_test = pd.DataFrame(np_preds_test, columns=['Prediction'])\n",
        "df_preds_test['ID'] = df_preds_test.index + 1\n",
        "df_preds_test[['ID', 'Prediction']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a27eb2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating output .csv\n",
        "output_filename = \"base_combined_test_submission.csv\"\n",
        "df_preds_test[['ID', 'Prediction']].to_csv(output_filename, index=False)\n",
        "print(f\"Successfully created submission file: {output_filename}, DON'T FORGET TO DELETE THE EMPTY LINE FROM END!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
